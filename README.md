# ğŸ  Costa Rica MLS - Autonomous Property System

A **fully autonomous, maintenance-free** property registry system for Costa Rica real estate. Deployed on IPFS with $0 ongoing costs, featuring automated property scraping, serverless PDF generation, and automated email campaigns.

**Status**: âœ… Production Ready | 402+ Real Properties | Last Updated: December 10, 2025

## ğŸ“š Quick Navigation

- ğŸš€ **[Getting Started](#quick-start)** - Setup & deployment
- ğŸ—ï¸ **[Architecture](#architecture)** - System design & tech stack
- ğŸ”§ **[Configuration](#configuration)** - Setup instructions
- ğŸ¯ **[Development](#development)** - Local development workflow
- ğŸ“– **[Full Documentation](#documentation)** - Detailed guides

---

## ğŸš€ Key Features

- âœ… **Autonomous Property Scraping** (every 6 hours via GitHub Actions)
- âœ… **6 Active Data Sources** (Encuentra24, Craigslist, OmniMLS, Coldwell Banker, RE/MAX, Immo)
- âœ… **Real-Time Price Tracking** (detects price changes & trends)
- âœ… **Government Data Enrichment** (BCCR, Registro Nacional, municipal data - framework ready)
- âœ… **Automated Email Campaigns** (category-based to subscribers)
- âœ… **Serverless PDF Generation** (AWS Lambda)
- âœ… **IPFS Static Hosting** (decentralized, censorship-resistant)
- âœ… **PayPal + Blockchain Payments** (Polygon USDC support)
- âœ… **99.9% Uptime** (via IPFS keepalive daemon)

---

## ğŸ¯ Zero-Cost Architecture

This system runs **completely autonomously** on free/freemium services:

| Service | Cost | Usage |
|---------|------|-------|
| GitHub Actions | $0/month | 2000 min/month (scraping, building, deploying) |
| AWS Lambda | $0/month | 1M requests/month (PDF generation) |
| IPFS Hosting | $0/month | Decentralized static site |
| EmailJS | $0/month | 200 emails/month |
| GitHub Database | $0/month | Unlimited JSON files |
| **TOTAL** | **$0/month** | âœ… Fully autonomous |

---

## ğŸ—ï¸ Architecture

### System Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AUTOMATION LAYER                       â”‚
â”‚         (GitHub Actions - Every 6 Hours)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Property Scraping     â†’  Deduplication  â†’  Enrichment    â”‚
â”‚  â”œâ”€ Encuentra24            SHA-256 hash      â”œâ”€ BCCR data  â”‚
â”‚  â”œâ”€ Craigslist            Stored: active      â”œâ”€ Property   â”‚
â”‚  â”œâ”€ OmniMLS                       pending      â”‚  records    â”‚
â”‚  â”œâ”€ Coldwell Banker                sold        â”œâ”€ Tax data   â”‚
â”‚  â”œâ”€ RE/MAX                       archived      â””â”€ Risk data  â”‚
â”‚  â””â”€ Immo                                                     â”‚
â”‚                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Email Campaigns  â†’  Database Commit  â†’  IPFS Deploy       â”‚
â”‚  Category-based       GitHub JSON         Web + Pinata      â”‚
â”‚  PDF attachments      Version control     Keepalive daemon  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    FRONTEND (React SPA on IPFS)      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  â€¢ Property Search & Filtering       â”‚
    â”‚  â€¢ Price History Charts              â”‚
    â”‚  â€¢ Premium Report Generation         â”‚
    â”‚  â€¢ PayPal & Crypto Payments          â”‚
    â”‚  â€¢ Email Subscription Management     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Frontend**: React 18 + TypeScript + Vite  
**Database**: GitHub JSON files (version-controlled, free)  
**Scraping**: Node.js + Puppeteer (for JavaScript-heavy sites)  
**Enrichment**: API integration framework (BCCR, Registro Nacional, etc.)  
**Hosting**: IPFS (decentralized) + Pinata (pinning service)  
**Automation**: GitHub Actions (CI/CD)  
**Monitoring**: Winston logging + structured JSON output  
**Testing**: Jest + integration tests  
**Code Quality**: ESLint + Prettier + TypeScript strict mode  

---

## ğŸ“ Project Structure

```
CR_MLS_New/
â”œâ”€â”€ .github/workflows/          # GitHub Actions automation
â”‚   â””â”€â”€ autonomous-mls.yml      # Main scrape â†’ enrich â†’ deploy pipeline
â”œâ”€â”€ client/                     # React SPA for IPFS deployment
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/              # Route pages
â”‚   â”‚   â”œâ”€â”€ services/           # API clients (GitHub Database)
â”‚   â”‚   â”œâ”€â”€ contexts/           # React Context providers
â”‚   â”‚   â”œâ”€â”€ hooks/              # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ types/              # TypeScript definitions
â”‚   â”‚   â””â”€â”€ utils/              # Encryption, validation
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ database/           # Synced property data
â”‚   â”œâ”€â”€ dist/                   # Production build
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ database/                   # JSON database files (GitHub-stored)
â”‚   â”œâ”€â”€ properties/
â”‚   â”‚   â”œâ”€â”€ active.json         # Current listings (402 properties)
â”‚   â”‚   â”œâ”€â”€ pending.json        # Awaiting approval
â”‚   â”‚   â”œâ”€â”€ sold.json           # Historical sales
â”‚   â”‚   â””â”€â”€ archived.json       # Old/expired
â”‚   â”œâ”€â”€ scraping/
â”‚   â”‚   â”œâ”€â”€ sources.json        # 6 active sources config
â”‚   â”‚   â”œâ”€â”€ last-run.json       # Latest scraping stats
â”‚   â”‚   â””â”€â”€ errors.json         # Error history
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ categories.json     # Property types & pricing
â”‚   â”‚   â”œâ”€â”€ regions.json        # Costa Rica zones
â”‚   â”‚   â””â”€â”€ automation.json     # Email settings
â”‚   â”œâ”€â”€ subscribers/            # Email subscribers
â”‚   â”œâ”€â”€ price-history.json      # Price tracking data
â”‚   â””â”€â”€ deployments/            # IPFS deployment history
â”œâ”€â”€ scripts/                    # Node.js automation & utilities
â”‚   â”œâ”€â”€ scraper.js              # Multi-source property scraper
â”‚   â”œâ”€â”€ validate-properties.js  # Data validation & sanitization
â”‚   â”œâ”€â”€ property-purger.js      # 90-day cleanup (runs weekly)
â”‚   â”œâ”€â”€ email-campaigns.js      # Automated email sender
â”‚   â”œâ”€â”€ real-data-pipeline.js   # Full enrichment pipeline
â”‚   â”œâ”€â”€ sync-database-to-client.sh  # Dev helper
â”‚   â”œâ”€â”€ recovery.js             # Error recovery procedures
â”‚   â””â”€â”€ [15+ test & debug scripts]
â”œâ”€â”€ src/                        # Backend utilities & enrichment
â”‚   â”œâ”€â”€ config.ts               # Configuration management
â”‚   â”œâ”€â”€ types.ts                # TypeScript interfaces
â”‚   â”œâ”€â”€ sources/                # Individual scrapers
â”‚   â”œâ”€â”€ services/               # Business logic
â”‚   â”œâ”€â”€ enrich/                 # Enrichment pipeline (BCCR, etc.)
â”‚   â””â”€â”€ utils/                  # Logger, HTTP client, helpers
â”œâ”€â”€ serverless/                 # AWS Lambda functions
â”‚   â””â”€â”€ pdf-generator/          # PDF report generation
â”œâ”€â”€ contracts/                  # Polygon smart contracts
â”‚   â””â”€â”€ PropertyEscrow.sol       # Crypto payment handling
â”œâ”€â”€ logs/                       # Pipeline execution logs
â”œâ”€â”€ public/                     # Static files
â”‚   â””â”€â”€ pdfs/                   # Generated PDF reports
â”œâ”€â”€ .husky/                     # Git hooks (pre-commit)
â”œâ”€â”€ tsconfig.json               # TypeScript configuration (strict mode)
â”œâ”€â”€ .prettierrc.json            # Code formatting rules
â”œâ”€â”€ .eslintrc.json              # Linting rules
â”œâ”€â”€ jest.config.js              # Testing configuration
â”œâ”€â”€ CODEOWNERS                  # Code ownership & approvals
â””â”€â”€ [Documentation files below]
```

---

## ğŸ”§ Configuration

### Database Configuration Files

**`database/config/categories.json`** - Property types & pricing
```json
{
  "residential": { "name": "Residential", "email_price": 5, "auto_email": true },
  "commercial": { "name": "Commercial", "email_price": 12, "auto_email": true },
  "land": { "name": "Land", "email_price": 8, "auto_email": true },
  "luxury": { "name": "Luxury", "email_price": 15, "auto_email": true }
}
```

**`database/scraping/sources.json`** - Active property sources
- Encuentra24 (primary API)
- Craigslist (RSS + scraping)
- OmniMLS (with Costa Rica filtering)
- Coldwell Banker CR
- RE/MAX Costa Rica
- Immo Costa Rica

**`database/config/automation.json`** - Email & scraping schedule
- Scraping: Every 6 hours (00:00, 06:00, 12:00, 18:00 UTC)
- Purging: Weekly Sundays at 2 AM UTC
- Email: After each scraping cycle

---

## ğŸš€ Quick Start

### 1. Prerequisites
- Node.js 18+
- npm or yarn
- Git
- IPFS daemon (optional, for local deployment)

### 2. Clone & Setup
```bash
git clone https://github.com/urmt/CR_MLS.git
cd CR_MLS_New
npm install
cd client && npm install && cd ..
```

### 3. Set GitHub Secrets
Go to: https://github.com/urmt/CR_MLS/settings/secrets/actions

Add these secrets:
```
PINATA_API_KEY=<your-pinata-key>
PINATA_SECRET=<your-pinata-secret>
EMAILJS_SERVICE_ID=<your-emailjs-service>
EMAILJS_TEMPLATE_ID=<your-emailjs-template>
EMAILJS_PUBLIC_KEY=<your-emailjs-key>
```

âš ï¸ **IMPORTANT**: Never commit API keys. Always use GitHub Secrets.

### 4. Local Development
```bash
# Pull latest scraped data
git pull origin main

# Sync database to client
./scripts/sync-database-to-client.sh

# Start dev server
cd client && npm run dev
# Opens on http://localhost:5173
```

### 5. Run Validation & Tests
```bash
npm run validate    # Check property data integrity
npm run test        # Run unit tests
npm test:integration  # Run integration tests
npm run lint        # Check code quality
npm run format      # Auto-format code
```

### 6. Manual Scraping (if needed)
```bash
node scripts/scraper.js        # Scrape all sources
node scripts/property-purger.js  # Clean 90+ day old properties
npm run validate               # Verify data
git add database/ && git commit -m "Manual property update"
```

---

## ğŸ”„ Automation Workflows

### GitHub Actions Automation (Every 6 Hours)

The `.github/workflows/autonomous-mls.yml` workflow runs:

1. **Property Scraping** (10-20 minutes)
   - Scrapes all 6 active sources in parallel
   - Deduplicates properties
   - Stores in `database/properties/pending.json`

2. **Approval & Move** (automatic)
   - Moves pending â†’ active properties
   - Commits to GitHub

3. **Property Purging** (Sundays only)
   - Removes properties 90+ days old
   - Cleans up database

4. **Email Campaigns**
   - Sends new listings to subscribers
   - Category-based distribution
   - PDF attachments via AWS Lambda

5. **IPFS Deployment**
   - Builds React client
   - Deploys to local IPFS node
   - Pins to Pinata
   - Announces to DHT

### Manual Workflow Triggers
```bash
# Trigger scraping only
gh workflow run "Autonomous Costa Rica MLS" \
  --repo urmt/CR_MLS \
  --field action=scrape

# Trigger full workflow
gh workflow run "Autonomous Costa Rica MLS" \
  --repo urmt/CR_MLS \
  --field action=full

# Check recent runs
gh run list --workflow="autonomous-mls.yml" --repo urmt/CR_MLS
```

---

## ğŸ§ª Development

### Code Quality Standards

All commits must pass:
```bash
npm run lint        # ESLint - no errors allowed
npm run format      # Prettier - consistent formatting
npm run type-check  # TypeScript - strict mode (no `any`)
npm test           # Jest - all tests must pass
npm run validate   # Property data integrity
```

### Pre-commit Hooks

The project uses Husky to prevent bad commits:
- âŒ Detects exposed API keys
- âŒ Rejects commits to main/master
- âœ… Auto-runs ESLint on staged files
- âœ… Checks file sizes (warn >10MB)

### Adding New Property Sources

1. **Create scraper** in `src/sources/newsource.ts`
2. **Add configuration** to `database/scraping/sources.json`
3. **Test scraper** with: `node scripts/test-single-source.js newsource`
4. **Update documentation** in `README-OMNIMLS.md` template
5. **Submit PR** for review

### Testing

```bash
# Run all tests
npm test

# Watch mode (re-run on changes)
npm test -- --watch

# Coverage report
npm test -- --coverage

# Integration tests only
npm run test:integration

# Run specific test file
npm test -- scripts/scraper.test.js
```

---

## ğŸ“– Documentation

### Main Guides
- **[START-HERE.md](./START-HERE.md)** - Current status & next steps â­ **START HERE**
- **[WARP.md](./WARP.md)** - Technical architecture & APIs
- **[DEPLOYMENT-SUMMARY.md](./DEPLOYMENT-SUMMARY.md)** - Current deployment details
- **[PROJECT-LOG.md](./PROJECT-LOG.md)** - Development history & milestones

### Integration Guides
- **[README-OMNIMLS.md](./README-OMNIMLS.md)** - OmniMLS scraper integration
- **[README-REAL-DATA.md](./README-REAL-DATA.md)** - Government API enrichment
- **[database/README.md](./database/README.md)** - Database structure

### Additional Resources
- **[CONTRIBUTING.md](./CONTRIBUTING.md)** - Development guidelines
- **[SECURITY.md](./SECURITY.md)** - Security policies & secret management
- **[API-KEYS.md](./API-KEYS.md)** - How to obtain API credentials

---

## ğŸ” Security

- **Pre-commit hooks** prevent accidental credential commits
- **GitHub Secrets** for all sensitive credentials (never in code)
- **Client-side encryption** for stored credentials (CryptoJS)
- **AWS IAM roles** restrict Lambda function permissions
- **PayPal sandbox mode** for development

### Credential Rotation
GitHub API keys should be rotated every 90 days:
1. Generate new credentials in provider dashboard
2. Update GitHub Secrets
3. Delete old credentials
4. Verify in next automated run

âš ï¸ **If Credentials Compromised**:
```bash
# 1. Revoke old credentials immediately
# 2. Generate new ones
# 3. Update GitHub Secrets
# 4. Run recovery procedure
git pull origin main
./scripts/recovery.js rotate-credentials
git push origin main
```

---

## ğŸŒ IPFS Deployment

### Live URL
- **Primary**: https://w3s.link/ipfs/[CURRENT_CID]
- **Pinata**: https://gateway.pinata.cloud/ipfs/[CURRENT_CID]
- **IPFS.io**: https://ipfs.io/ipfs/[CURRENT_CID]

Deployment history in: `database/deployments/ipfs-history.json`

### Local IPFS Setup
```bash
# Install IPFS
brew install ipfs  # macOS
# OR
sudo apt install go-ipfs  # Linux

# Initialize
ipfs init
ipfs daemon &

# Deploy locally
./scripts/deploy-ipfs.sh

# Pin to Pinata (automatic via GitHub Actions)
```

### Keepalive Daemon (Linux)
Maintains IPFS availability via systemd service:
```bash
~/.ipfs-keepalive/manage.sh status   # Check status
~/.ipfs-keepalive/manage.sh follow   # View live logs
~/.ipfs-keepalive/manage.sh restart  # Restart service
```

---

## ğŸ’° Revenue Model

Users can access property contact information via:
- **$5**: Residential properties (PayPal/USDC)
- **$12**: Commercial properties (PayPal/USDC)
- **$15**: Luxury properties (PayPal/USDC)

Payments processed via:
- **PayPal** (direct integration)
- **Polygon USDC** (via smart contract)

---

## ğŸš¨ Monitoring & Alerts

### Health Checks
```bash
# Check GitHub Actions status
gh run list --workflow="autonomous-mls.yml" --repo urmt/CR_MLS

# Check IPFS availability
curl https://ipfs.io/ipfs/[CID]/index.html

# Check database freshness
git log --oneline -n 10 database/properties/

# View recent logs
ls -lh logs/pipeline-*.json | tail -5
```

### Troubleshooting
- **0 properties scraped**: Check `logs/pipeline-latest.json` for errors
- **IPFS not accessible**: Verify Pinata pinning in GitHub Actions logs
- **Email not sending**: Check EmailJS credentials in GitHub Secrets
- **Data corruption**: Run `./scripts/recovery.js repair-database`

---

## ğŸ¤ Contributing

1. **Create feature branch** (never commit to main)
2. **Make changes** following code standards
3. **Run tests**: `npm test && npm run validate`
4. **Submit PR** with description of changes
5. **Code review** before merging
6. **Deploy** to production via GitHub Actions

See [CONTRIBUTING.md](./CONTRIBUTING.md) for detailed guidelines.

---

## ğŸ“„ License

MIT License - Free to use and modify

---

## ğŸ“Š Current Status

| Component | Status | Last Update |
|-----------|--------|-------------|
| Property Scraping | âœ… Active | Runs every 6 hours |
| Database | âœ… 402 properties | Dec 10, 2025 |
| IPFS Deployment | âœ… Live | Auto-updates with scraping |
| Email Campaigns | âœ… Working | Runs after scraping |
| PDF Generation | âœ… AWS Lambda | On-demand generation |
| Code Quality | âœ… Strict TypeScript | All tests passing |
| Pre-commit Hooks | âœ… Installed | Prevents credentials leaks |

---

**ğŸŒ This system operates autonomously with zero manual intervention required!** ğŸš€

Last Updated: December 10, 2025  
Questions? See [START-HERE.md](./START-HERE.md) for current status and next steps.

Visit the live site: `https://ipfs.io/ipfs/[your-hash]`